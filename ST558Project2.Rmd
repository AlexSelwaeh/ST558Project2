---
title: "ST558 Project 2"
author: "Alex Selwaeh and Zichang Xiang"
date: "7/1/2021"
output: html_document  
params: 
      dow: "Monday"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction Section

The purpose of this project is to create predictive models and automate R Markdown reports. The data we will use is the number of Bike-sharing users aggregated on daily basis from the Capital Bikeshare system in 2011 and 2012. In this data set, there are 16 variables that are related to bike rental counts. The variables we will use include season, year (yr), mnth, holiday, weekday, workingday, weathersit, hum, atemp, temp, casual, registered, and count (cnt). To model response counts (cnt), we will use linear regression models and ensemble tree methods (random forest method and boosted tree method).

## Data

```{r librarydefs, message=FALSE}
#load packages
library(corrplot)
library(ggplot2)
library(cowplot)
library(modelr)
library(readr)
library(dplyr)
library(knitr)
library(caret)
library(tidyr)
library(purrr)
library(gbm)
library(randomForest)
library(leaps)

```

```{r readin, message=FALSE}
#read in data
dayData <- read_csv("day.csv")
dayData

#check for missing values
anyNA(dayData)

#create for loop to subset data for each weekday
status<-vector()

for (i in seq_len(nrow(dayData))){
  if(dayData$weekday[i] == 1){
    status[i] <- "Monday"
  } else if (dayData$weekday[i] == 2){
    status[i] <- "Tuesday"
  } else if (dayData$weekday[i] == 3){
    status[i] <- "Wednesday"
  } else if (dayData$weekday[i] == 4){
    status[i] <- "Thursday"
  } else if (dayData$weekday[i] == 5){
    status[i] <- "Friday"
  } else if (dayData$weekday[i] == 6){
    status[i] <- "Saturday"
  } else {
    status[i] <- "Sunday"
  }
}

dayData$status <- status
#data for the day specified in params
dayData1 <- dayData
paramsData <- dayData %>% filter(status == params$dow)

#Create columns to represent the categorical columns as mentioned in READ.ME
paramsData <- paramsData %>%
  # Add columns to represent the categorical columns as mentioned in READ.ME.
  mutate(SeasonType = ifelse(season == 1, "spring", ifelse(season == 2, "summer", ifelse(season == 3, "fall", "winter"))), yearType= ifelse(yr == 0, "2011", "2012"), workingdayType= ifelse(workingday == 1, "Working Day", "Non WorkingDay"),weathersitType= ifelse(weathersit == 1, "Clear", ifelse(weathersit == 2, "Mist", ifelse(weathersit == 3, "Light Snow", "HeavyRain"))))

#convert month from numerical to categorical charcter  
paramsData$mnth1 <- as.character(paramsData$mnth)

```

```{r setseeds}
#split data set into training and test sets
set.seed(1)
train <- sample(1:nrow(paramsData), size = nrow(paramsData)*0.7)
test <- dplyr::setdiff(1:nrow(paramsData), train)

train <- paramsData[train, ]
test <- paramsData[test, ]

train
test
```

## Summarizations

### Summary Statistics

Summary statistics give us a quick look of our data. For our case, we can find out the average number of bike rentals per season.

```{r summarytable}
# Create a table of summary stats.
seasonSummary <- train %>% 
  # Select the seasone and cnt columns.
  select(SeasonType, cnt) %>%
  # Group by season
  group_by(SeasonType) %>%
  # Get summary statistics for total users by season.
  summarize("Min." = min(cnt),
            "1st Quartile" = quantile(cnt, 0.25),
            "Median" = quantile(cnt, 0.5),
            "Mean" = mean(cnt),
            "3rd Quartile" = quantile(cnt, 0.75),
            "Max" = max(cnt),
            "Std. Dev." = sd(cnt)
            )

# Display a table of the summary stats.
knitr::kable(seasonSummary, 
             caption=paste("Summary Statistics for total users",
                           "By Season"),
             digits=2)
```

#### Contingency Tables

A continuity table shows the relationship between two categorical variables. In our case, we can determine whether the season and weather are related, and whether the season and workday are related.

```{r contingencytables}
#create contingency tables
kable(table(train$SeasonType, train$weathersitType))
kable(table(train$SeasonType, train$workingdayType))
```

### Plots

#### Correlation Plot

Correlation plot shows the strength of a relationship between two variables. In our case, we can identify which variables are highly correlated with one another, especially with the response, the number of bikes rented.

```{r corrplot}

#create correlation plot
#corr <- cor(train[, -c(1,2,7,17:22)])
#head(round(corr, 2))
#corrplot(corr, type = "upper", method = "pie")

```

Let's examine the correlations among the quantitative variables, create correlation plot excluding qualitative variables.
It's apparent how temp and atemp are strongly correlated and this will cause multicollineariy, therefore we can safely drop one of the two varaibles. Also, for same reasoning we will drop registered and casual since they are directly related to the contribution of cnt. The only quanitative variable to include in the linear regression analysis will be "atemp".

#### Histograms

Histograms are used to summarize distributions of variables. In our case, we are trying to find out whether the change in each variable has an impact on the number of bikes rented.

```{r histo, message=FALSE}
#create boxplots for selected variables (referenced from https://drsimonj.svbtle.com/quick-plot-of-all-variables)
#reshape the data set
reshape <- train %>% keep(is.numeric) %>% gather() 
#plot the density plot
g <- ggplot(reshape, aes(x = value))
g + facet_wrap(~ key, scales = "free") + geom_density()

```

#### Boxplots

Boxplots show the shape of the distribution of each variable. By looking at the boxplots below, we can see how each variable affects the number of bikes rented.

```{r boxplots, message=FALSE}
#create boxplot for each variables
attach(train)
par(mfrow = c(1,4))
boxplot(season, xlab = "season")
boxplot(mnth, xlab =" mnth")
boxplot(weathersit, xlab = "weathersit")
boxplot(windspeed, xlab = " windspreed")
boxplot(yr, xlab = "yr")
boxplot(temp, xlab = "temp")
boxplot(atemp, xlab = "atemp")

#remove outliers
train <- train[!abs(train$windspeed)>0.4, ]
```

Boxplot with the number of users on the y-axis (wether casual,registered or total users) and the season on the x-axis - We can inspect the trend of users across seasons using these plots. Notice that the biggest contribution towards total number of users comes from the registered users which is expected. The most active seasons for that `r params$dow` is the fall season and the least active season is the spring.

```{r multiboxplots}
#create boxplots
plot11 <- ggplot(train, aes(SeasonType,
                                   cnt,
                                   color=cnt)) +
  geom_boxplot() + 
  # Jitter the points to add a little more info to the boxplot.
  geom_jitter() + 
  # Add labels to the axes.
  scale_x_discrete("Season") + scale_y_continuous("Total Users") +
  ggtitle("Total Users by Season") + theme(legend.position="none")
plot11
plot12 <- ggplot(train, aes(SeasonType,
                                   casual,
                                   color=cnt)) +
  geom_boxplot() + 
  # Jitter the points to add a little more info to the boxplot.
  geom_jitter() + 
  # Add labels to the axes.
  scale_x_discrete("Season") + scale_y_continuous("Casual Users") +
  ggtitle("Casual Users by Season") + theme(legend.position="none")
plot12
plot13 <- ggplot(train, aes(SeasonType,
                                   registered,
                                   color=cnt)) +
  geom_boxplot() + 
  # Jitter the points to add a little more info to the boxplot.
  geom_jitter() + 
  # Add labels to the axes.
  scale_x_discrete("Season") + scale_y_continuous("Registered Users") +
  ggtitle("Registered Users by Season") + theme(legend.position="none")
plot13
plot_grid(plot13, plot12,plot11, ncol=3)

```

#### Scatter plots  

Scatter plot with the total number of users on the y-axis and the temperature, wind speed, humidity on the x-axis - We can inspect the trend of total users across these variables and notice that humidity almost has a slight negative effect on the total number of users. Also it's noticeable that the wind speed has a slight negative effect on the total number of users .  
```{r scatterplots}
#create scatter plots
plot21 <- ggplot(train, aes(temp,
                                   cnt,
                                   color=cnt)) + 
  geom_point(size=4, alpha=0.75) + scale_color_gradient(low="blue", high="red") + 
  theme(legend.position="none") + geom_smooth(method=lm, formula=y~x, color="black") + 
  scale_x_continuous("Temprature") + 
  scale_y_continuous("Total Users") + 
  ggtitle("Temprature. vs. Total Users")
plot21

plot22 <- ggplot(train, aes(windspeed,
                                   cnt,
                                   color=cnt)) + 
  geom_point(size=4, alpha=0.75) + scale_color_gradient(low="blue", high="red") + 
  theme(legend.position="none") + geom_smooth(method=lm, formula=y~x, color="black") + 
  scale_x_continuous("Wind Speed") + 
  scale_y_continuous("Total Users") + 
  ggtitle("Wind Speed vs. Total Users")
plot22

plot23 <- ggplot(train, aes(hum,
                                   cnt,
                                   color=cnt)) + 
  geom_point(size=4, alpha=0.75) + scale_color_gradient(low="blue", high="red") + 
  theme(legend.position="none") + geom_smooth(method=lm, formula=y~x, color="black") + 
  scale_x_continuous("Humidity") + 
  scale_y_continuous("Total Users") + 
  ggtitle("Humidity vs. Total Users")
plot23

plot_grid(plot21, plot22, plot23,ncol=3)
```

scatterplot with the number of users on the y-axis and the month on the x-axis, We can inspect the trend of users across months using this plot.

```{r scat}
plot31 <- ggplot(paramsData, aes(x = mnth, y = casual)) + geom_point() +
    geom_smooth() +
    geom_smooth(method = lm, col = "Red")
plot32 <- ggplot(paramsData, aes(x = mnth, y = registered)) + geom_point() +
    geom_smooth() +
    geom_smooth(method = lm, col = "Red")
plot33 <- ggplot(paramsData, aes(x = mnth, y = cnt)) + geom_point() +
    geom_smooth() +
    geom_smooth(method = lm, col = "Red")
plot_grid(plot31, plot32, plot33,ncol=3)

```

## Modeling

Linear Regression analyzes the relationship(s) between a response variable and one or more of the predictor variables and their interactions. It can determine how strong or weak is the relationship between these variables, it can identify which of the predictor variables contribute the most to the response and it can help in predicting future responses. Linear regression could be simple which includes only one predictor variable in the fitted model, could be multiple linear regression involving more than one predictor and there is general linear models where the reponse and predictors could be qualitative and not only quantitative. Linear regression model fits are done with lm() function in R, lm() is a linear regression model that uses a straight line to describe the relationship between variables. It finds the line of best fit through the given data by searching for the value of the coefficients which represent the linear regression model and knows as beta_0, beta_1, beta_2 and responsible for minimizing the total error of the model (MSE for quantitative response analysis).

### Modeling of the first group member

```{r partner11}
fitlm1 <- train(cnt ~ atemp*season*yr, data = train, 
                method = "lm", 
                preProcess = c("center", "scale"),
                trControl = trainControl(method = "cv", number = 10))
fitlm1

fitlm2 <- train(cnt ~ atemp + yr + season +windspeed+mnth+holiday+weathersit, data = train, 
                method = "lm", 
                preProcess = c("center", "scale"),
                trControl = trainControl(method = "cv", number = 10))
fitlm2

fitlm3 <- train(cnt ~ atemp + yr + season +windspeed+weathersit+mnth, data = train, 
                method = "lm", 
                preProcess = c("center", "scale"),
                trControl = trainControl(method = "cv", number = 10))
fitlm3

fitlm4 <- train(cnt ~ atemp + yr + I(yr^2), data = train, 
                method = "lm", 
                preProcess = c("center", "scale"),
                trControl = trainControl(method = "cv", number = 10))
fitlm4

```

```{r partner12}
pred.fitlm1 <- predict(fitlm1, newdata = test)
rmse1<-postResample(pred.fitlm1, obs = test$cnt)


pred.fitlm2 <- predict(fitlm2, newdata = data.frame(test))
rmse2<-postResample(pred.fitlm2, obs = test$cnt)

pred.fitlm3 <- predict(fitlm3, newdata = data.frame(test))
rmse3<-postResample(pred.fitlm3, obs = test$cnt)

pred.fitlm4 <- predict(fitlm4, newdata = data.frame(test))
rmse4<-postResample(pred.fitlm4, obs = test$cnt)

kable(data.frame(rmse1[1], rmse2[1], rmse3[1],rmse4[1]))

```

Summary for the model fit with the lowest cross validation test error(RMSE) : fitlm3
```{r partner13}

summary(fitlm3)

```

A different approach for selecting the best model for prediction purposes is minimizing test MSE.    

```{r partner14}
# select multiple random models in addition to the one we picked from the previous study being the first fit(glm1Fit)
glm1Fit <- lm(cnt ~ atemp + yr + season +windspeed+weathersit+mnth, data = train)
glm2Fit <- lm(cnt ~ atemp:yr, data = train)
glm3Fit <- lm(cnt ~ atemp + yr + season, data = train)
glm4Fit <- lm(cnt ~ atemp*yr*season, data = train)
glm5Fit <- lm(cnt ~ atemp+yr+I(yr^2), data = train)

model <- c(("glm1Fit"),("glm2Fit"),("glm3Fit"),("glm4Fit"),("glm5Fit"))
  
trainMSE <- c(rmse(glm1Fit, train),
rmse(glm2Fit, train),
rmse(glm3Fit, train),
rmse(glm4Fit, train),
rmse(glm4Fit, train)
)
testMSE <- c(rmse(glm1Fit, test),
rmse(glm2Fit, test),
rmse(glm3Fit, test),
rmse(glm4Fit, test),
rmse(glm5Fit, test)
)
MSEdf <- data.frame(model, trainMSE, testMSE)
MSEdf <- MSEdf %>% arrange(testMSE)
kable(data.frame(MSEdf),caption = "Table showing glm1Fit is the best fit")

```

Knowing that we can't fully trust test MSE values in order to decide on a model, we will go a step further in developing AIC,BIC and Rsquare Criterias. Using the function from module 9  

```{r partner15}
compareFitStats <- function(newfit1, newfit2,newfit3,newfit4,newfit5){
    require(MuMIn)
    fitStats <- data.frame(fitStat = c("Adj R Square", "AIC", "AICc", "BIC"),
        col1 = round(c(summary(newfit1)$adj.r.squared, AIC(newfit1), 
                                    MuMIn::AICc(newfit1), BIC(newfit1)), 3),
            col2 = round(c(summary(newfit2)$adj.r.squared, AIC(newfit2), 
                                    MuMIn::AICc(newfit2), BIC(newfit2)), 3),
                col3 = round(c(summary(newfit3)$adj.r.squared, AIC(newfit3), 
                                    MuMIn::AICc(newfit3), BIC(newfit3)), 3),
                    col4 = round(c(summary(newfit4)$adj.r.squared, AIC(newfit4), 
                                    MuMIn::AICc(newfit4), BIC(newfit4)), 3),
                        col5 = round(c(summary(newfit5)$adj.r.squared, AIC(newfit5), 
                                    MuMIn::AICc(newfit5), BIC(newfit5)),3))
    #put names on returned df
    calls <- as.list(match.call())
    calls[[1]] <- NULL
    names(fitStats)[2:6] <- unlist(calls)
    fitStats
}

kable(data.frame(compareFitStats(glm1Fit,glm2Fit,glm3Fit,glm4Fit,glm5Fit)),caption = "Table showing Rsquared,AIC,AICc and BIC criteria")

```
Again, the calculated criterias shows that glm1Fit (which is the same as fitlm3 model) which represents the 6 predictors , is the best model fit selected.  

An extra step to prove that our choice of glm1Fit as the best fit, here I decided to use the method explained in section 6.5.3 of the book: Choosing Among Models Using the Validation Set Approach (test Dataset) and Cross-Validation.

```{r partner16}
# we apply regsubsets() to the training set in order to perform best subset selection.
library(leaps)
regfit.best=regsubsets (cnt ~ temp + yr + season +windspeed+mnth+holiday+weathersit+atemp,data=train)
summary(regfit.best)

test.mat=model.matrix(cnt ~ temp + yr + season +windspeed+mnth+holiday+weathersit+atemp,data=test)

val.errors =rep(NA ,8)
for(i in 1:8)
{
    coefi=coef(regfit.best ,id=i)
    pred=test.mat[,names(coefi)]%*%coefi
    val.errors[i]=mean(( test$cnt-pred)^2)
}

val.errors

```
Displaying the Selected model with the calculted regression coefficients.  

```{r}
#coef(regfit.best ,which.min(val.errors))
```
Also another extra verification step by doing the Partial least squares method.  

```{r}
library(pls)
set.seed(222)
 pls.fit=plsr(cnt~ atemp + yr + season +windspeed+mnth+weathersit, data=train, scale=TRUE ,
validation ="CV")  

summary (pls.fit)


validationplot(pls.fit ,val.type="MSEP")

```

The lowest cross-validation error occurs when only M = 4.We now evaluate the corresponding test MSE.

```{r}
pls.pred=predict (pls.fit ,test,ncomp =4)
mean((pls.pred -test$cnt)^2)
MSE.val2 <- sqrt(mean((pls.pred -test$cnt)^2))
MSE.val2
```
We noticed that PLS resulted in a similar value to the previous methods and approaches used.  

#### Random Forest  
Random forest is a tree-based method for regression or classification which involves producing multiple trees known as decision trees to yield a single adequate prediction. ISLR book mentions about decision trees "When building these decision trees, each time a split in a tree is considered, a random sample of m predictors is chosen as split candidates from the full set of p predictors. The split is allowed to use only one of those m predictors. A fresh sample of
m predictors is taken at each split."


```{r rforest}
rfTree <- train(cnt ~ atemp + yr + season +windspeed+weathersit+mnth, data = train, method = "rf",
                trControl = trainControl(method = "repeatedcv", number = 10, repeats = 5),
                preProcess = c("center", "scale"))
rfTree

```

Perform prediction on our test data set  
```{r}
rfPred <- predict(rfTree, newdata = test)
rfresult <- postResample(rfPred, test$cnt)
rfresult

```

### Modeling of the second group member

```{r}
#use step function to select variables
select <- step(lm(cnt ~ 1, train), scope = cnt ~ season + yr + mnth + temp + atemp, direction = "both", k = log(nrow(train))) # here we use BIC because we set k equals to log(n)
#view the selected variables
colnames(select$model)
```

Considering the above result, the selected variables are cnt, atemp, yr, and season, as the model that includes these variables has the smallest BIC.

```{r}
#select models
set.seed(1)
fit1 <- train(cnt ~ season + yr  + workingday + weathersit + temp + atemp + windspeed, 
              data = train,
              method = "lm",
              preProcess = c("center", "scale"),
              trControl = trainControl(method = "cv", number = 10)
              )

fit2 <- train(cnt ~ season + yr + atemp, 
              data = train,
              method = "lm",
              preProcess = c("center", "scale"),
              trControl = trainControl(method = "cv", number = 10)
                )

fit3 <- train(cnt ~ season*yr*atemp, 
              data = train,
              method = "lm",
              preProcess = c("center", "scale"),
              trControl = trainControl(method = "cv", number = 10)
                )

fit4 <- train(cnt ~ I(season)^2 + I(yr)^2 + I(atemp)^2,
              data = train,
              method = "lm",
              preProcess = c("center", "scale"),
              trControl = trainControl(method = "cv", number = 10)
              )

fit5 <- train(cnt ~ I(yr)^2 + season *atemp,
              data = train,
              method = "lm",
              preProcess = c("center", "scale"),
              trControl = trainControl(method = "cv", number = 10)
              )

#compare each model
kable(data.frame(t(fit1$results), t(fit2$results), t(fit3$results), t(fit4$results), t(fit5$results)))

#check the fit
lmPred1 <- predict(fit1, newdata = test)
lmFit1 <- postResample(lmPred1, obs = test$cnt)

lmPred2 <- predict(fit2, newdata = test)
lmFit2 <- postResample(lmPred2, obs = test$cnt)

lmPred3 <- predict(fit3, newdata = test)
lmFit3 <- postResample(lmPred3, obs = test$cnt)

lmPred4 <- predict(fit4, newdata = test)
lmFit4 <- postResample(lmPred4, obs = test$cnt)

lmPred5 <- predict(fit5, newdata = test)
lmFit5 <- postResample(lmPred5, obs = test$cnt)
lmRMSE <- kable(data.frame(lmFit1[1], lmFit2[1], lmFit3[1], lmFit4[1], lmFit5[1]))
lmRMSE
#final model: fit5: cnt ~ I(yr)^2 + season *atemp
```

Five candidate linear regression models were fitted using the `train()` function and 10-fold cross-validation. In comparing their RMSE on the test sets, I chose the final model fit5 (cnt \~ I(yr)\^2 + season \*atemp), which has the lowest RMSE.

We use the train() function to fit the boosted tree model. First, we must give the model and data set we use. Next, we provide the method we use, which is "gbm". Then, we use the `preProcess()` function to standardize the data. Finally, we specify the type of cross-validation we wish to perform. In our case, we would like to perform repeated cross-validation with 10 folds for 5 times.

```{r results='hide'}
#fitting boosted tree model for counts
set.seed(1)
boostFit <- train(cnt ~ I(yr)^2 + season *atemp, 
                  data = train, 
                  method = "gbm", 
                  preProcess = c("center", "scale"),
                  trControl = trainControl(method = "repeatedcv", number = 10, repeats = 5))
```

```{r boostresults}
#view the results
boostFit$results
#view the best model
boostFit$bestTune
#predict cnt and calculate RMSE
boostPred <- predict(boostFit, newdata = test)
result <- postResample(boostPred, test$cnt)
boostRMSE <- result[1]
boostRMSE
```

### Comparison of all four models and Conclusion  
Based on the summarized results from the modeling fit portion of this project, we will choose partner_2 model fit as the best fit for this study.  

```{r}
results <- data.frame(MSEdf[1,3], lmFit5[1], boostRMSE,rfresult[1])
colnames(results) <- c("lmFit_1stMember", "lmFit_2ndMember", "Boost Tree","Random Forest")
kable(results)
```
